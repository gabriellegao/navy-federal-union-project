{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()\n",
    "import nltk.classify.util\n",
    "import pandas as pd\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NormalizedMessage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hey are you guys compatible with the security ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey are you guys compatible with the security ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you are welcome tons of locals with nf in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>please put a location in daytona thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am bout sick of yall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>davide moretti drove his way through the lane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how is it can disable all tabs and disable my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>defense apac pga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gee navy federal is a bank of be best aint it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>k we good here thanks but no thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the information that you provided i was alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>all usaa navy federal members who would like t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>brooks all usaa navy federal members who would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>when will allotments be deposited usaa already...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>you all about to upset me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ways to manage multiple corporate offices and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>atm rebate is the best thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>when that check hits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is navy federal down right now because my card...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    NormalizedMessage\n",
       "0   hey are you guys compatible with the security ...\n",
       "1   hey are you guys compatible with the security ...\n",
       "2   you are welcome tons of locals with nf in the ...\n",
       "3             please put a location in daytona thanks\n",
       "4                              i am bout sick of yall\n",
       "5   davide moretti drove his way through the lane ...\n",
       "6   how is it can disable all tabs and disable my ...\n",
       "7                                    defense apac pga\n",
       "8   gee navy federal is a bank of be best aint it ...\n",
       "9                 k we good here thanks but no thanks\n",
       "10  the information that you provided i was alread...\n",
       "11  all usaa navy federal members who would like t...\n",
       "12  brooks all usaa navy federal members who would...\n",
       "13  when will allotments be deposited usaa already...\n",
       "14                          you all about to upset me\n",
       "15  ways to manage multiple corporate offices and ...\n",
       "16                   atm rebate is the best thank you\n",
       "18                                                yes\n",
       "19                               when that check hits\n",
       "20  is navy federal down right now because my card..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset.csv\")\n",
    "data.head()\n",
    "data = data.drop(columns = ['IDNew','SocialNetwork','SenderUserId',\n",
    "                            'FollowersCount','Message','CreatedTime',\n",
    "                            'MessageType']).dropna()\n",
    "data_list = data['NormalizedMessage'].tolist()\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(word_list):\n",
    "    return dict([(word, True) for word in word_list])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    positive_fileids = movie_reviews.fileids('pos')\n",
    "    negative_fileids = movie_reviews.fileids('neg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positive_fileids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-818e90cf88ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Positive'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive_fileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Negative'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegative_fileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'positive_fileids' is not defined"
     ]
    }
   ],
   "source": [
    "features_positive = [(extract_features(data_list),'Positive') for f in positive_fileids]\n",
    "features_negative = [(extract_features(data_list),'Negative') for f in negative_fileids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test (80/20)\n",
    "threshold_factor = 0.8\n",
    "threshold_positive = int(threshold_factor * len(features_positive))\n",
    "threshold_negative = int(threshold_factor * len(features_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train = features_positive[:threshold_positive] + features_negative[:threshold_negative]\n",
    "# features_test = features_positive[threshold_positive:] + features_negative[threshold_negative:] Â \n",
    "# print(\"\\nNumber of training datapoints:\", len(features_train))\n",
    "# print(\"Number of test datapoints:\", len(features_test))\n",
    "\n",
    "features_train = features_positive[:threshold_positive] + features_negative[:threshold_negative]\n",
    "features_test = features_positive[threshold_positive:] + features_negative[threshold_negative:]\n",
    "print(\"\\nNumber of training datapoints:\", len(features_train))\n",
    "print(\"Number of test datapoints:\", len(features_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(features_train)\n",
    "print(\"\\nAccuracy of the classifier:\", nltk.classify.util.accuracy(classifier, features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop 10 most informative words:\")\n",
    "for item in classifier.most_informative_features()[:10]:\n",
    "    print(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPredictions:\")\n",
    "for review in data_list[:20]:\n",
    "    print(\"\\nReview:\", review)\n",
    "    probdist = classifier.prob_classify(extract_features(review.split()))\n",
    "    pred_sentiment = probdist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
